#!/bin/bash

# Python Ï§ëÏã¨ ÌÜµÌï© Ïã§Ìñâ Ïä§ÌÅ¨Î¶ΩÌä∏
# APIÎäî Î≥ÄÍ≤ΩÌïòÏßÄ ÏïäÍ≥† Î∞±ÏóîÎìú Î°úÏßÅÎßå PythonÏúºÎ°ú ÌÜµÌï©

echo "üöÄ Starting Python-centric integration..."

PROJECT_ROOT="/home/changeroa/projects/AI_QUIZ"
cd "$PROJECT_ROOT"

# 1. Ï§ëÎ≥µ ÌååÏùº ÏÇ≠Ï†ú
echo "üßπ Step 1: Removing duplicate JS files..."
bash cleanup/cleanup_duplicates.sh

# 2. ÏÑúÎπÑÏä§ ÌååÏùº ÏóÖÎç∞Ïù¥Ìä∏
echo "üìù Step 2: Updating service files..."

# pdfProcessingService.jsÎ•º Ï†ïÎ¶¨Îêú Î≤ÑÏ†ÑÏúºÎ°ú ÍµêÏ≤¥
if [ -f "backend/services/pdfProcessingService_cleaned.js" ]; then
    mv backend/services/pdfProcessingService.js backend/services/pdfProcessingService_backup.js
    mv backend/services/pdfProcessingService_cleaned.js backend/services/pdfProcessingService.js
    echo "‚úÖ Updated pdfProcessingService.js"
fi

# 3. Python ÏÑúÎπÑÏä§ ÌÜµÌï© ÌååÏùº ÏÉùÏÑ±
echo "üêç Step 3: Creating unified Python service..."

cat > backend/python_services/unified_service.py << 'EOF'
#!/usr/bin/env python3
"""
ÌÜµÌï© Python ÏÑúÎπÑÏä§ - Î™®Îì† PDF Ï≤òÎ¶¨, ÌÖçÏä§Ìä∏ Ï≤òÎ¶¨, ÏûÑÎ≤†Îî© Í∏∞Îä• ÌÜµÌï©
"""

import sys
import json
import argparse
from pdf_processor import AdvancedPDFProcessor, AdvancedTextPreprocessor
from embedding_service.embedding_generator import EmbeddingGenerator
from vector_search.qdrant_client import QdrantManager

class UnifiedService:
    def __init__(self):
        self.pdf_processor = AdvancedPDFProcessor()
        self.text_processor = AdvancedTextPreprocessor()
        self.embedding_generator = EmbeddingGenerator()
        self.vector_manager = QdrantManager()
    
    def process_pdf_complete(self, pdf_path, document_id, options):
        """PDF Ï≤òÎ¶¨ Ï†ÑÏ≤¥ ÌååÏù¥ÌîÑÎùºÏù∏"""
        try:
            # 1. PDF Ï∂îÏ∂ú
            pdf_result = self.pdf_processor.process_pdf(pdf_path)
            if not pdf_result["success"]:
                return {"success": False, "error": pdf_result.get("error")}
            
            # 2. ÌÖçÏä§Ìä∏ Ï≤òÎ¶¨ Î∞è Ï≤≠ÌÇπ
            text_result = self.text_processor.process_text(
                pdf_result["text"], 
                options.get("chunk_size", 500)
            )
            
            # 3. ÏûÑÎ≤†Îî© ÏÉùÏÑ±
            chunks_with_embeddings = []
            for chunk in text_result["chunks"]:
                embedding = self.embedding_generator.generate_embedding(
                    chunk["content"], 
                    prefix_type="passage"
                )
                chunk["embedding"] = embedding
                chunks_with_embeddings.append(chunk)
            
            # 4. Î≤°ÌÑ∞ DB Ï†ÄÏû•
            store_success = self.vector_manager.store_chunks(
                document_id, 
                chunks_with_embeddings
            )
            
            return {
                "success": True,
                "chunks": chunks_with_embeddings,
                "extractResult": {
                    "pageCount": pdf_result["page_count"]
                },
                "processing_options": options
            }
            
        except Exception as e:
            return {"success": False, "error": str(e)}

def main():
    parser = argparse.ArgumentParser(description='Unified PDF Processing Service')
    parser.add_argument('command', choices=['process', 'extract', 'embed'])
    parser.add_argument('--pdf', help='PDF file path')
    parser.add_argument('--doc-id', help='Document ID')
    parser.add_argument('--options', help='Processing options as JSON', default='{}')
    
    args = parser.parse_args()
    service = UnifiedService()
    
    if args.command == 'process':
        if not args.pdf or not args.doc_id:
            print(json.dumps({"error": "PDF path and document ID required"}))
            sys.exit(1)
        
        options = json.loads(args.options)
        result = service.process_pdf_complete(args.pdf, args.doc_id, options)
        print(json.dumps(result, ensure_ascii=False))
    
    elif args.command == 'extract':
        if not args.pdf:
            print(json.dumps({"error": "PDF path required"}))
            sys.exit(1)
        
        result = service.pdf_processor.process_pdf(args.pdf)
        print(json.dumps(result, ensure_ascii=False))

if __name__ == "__main__":
    main()
EOF

chmod +x backend/python_services/unified_service.py

# 4. Î∂àÌïÑÏöîÌïú Node.js Î™®Îìà Ï†úÍ±∞
echo "üóëÔ∏è  Step 4: Cleaning up Node.js dependencies..."

# package.jsonÏóêÏÑú Î∂àÌïÑÏöîÌïú ÏùòÏ°¥ÏÑ± Ï†úÍ±∞Î•º ÏúÑÌïú Î∞±ÏóÖ
cp backend/package.json backend/package_backup.json

# 5. ÌôòÍ≤Ω Î≥ÄÏàò ÏóÖÎç∞Ïù¥Ìä∏
echo "‚öôÔ∏è  Step 5: Updating environment configuration..."

if [ -f "backend/.env" ]; then
    # Python ÏÑúÎπÑÏä§ ÏÇ¨Ïö© ÌîåÎûòÍ∑∏ Ï∂îÍ∞Ä
    echo "" >> backend/.env
    echo "# Python Service Integration" >> backend/.env
    echo "USE_PYTHON_SERVICES=true" >> backend/.env
    echo "PYTHON_SERVICE_PATH=./python_services" >> backend/.env
fi

echo ""
echo "‚úÖ Integration completed!"
echo ""
echo "üìã Summary:"
echo "- Removed duplicate JS files for PDF processing, text processing, and embeddings"
echo "- Updated service files to use Python services exclusively"
echo "- Created unified Python service"
echo "- API endpoints remain unchanged"
echo ""
echo "‚ö†Ô∏è  Important:"
echo "1. Make sure Python dependencies are installed:"
echo "   cd backend/python_services && pip install -r requirements.txt"
echo "2. Test all API endpoints to ensure they work correctly"
echo "3. Original files are backed up in cleanup/backup_*"
